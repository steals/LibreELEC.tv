diff --git a/drivers/amlogic/video_dev/Kconfig b/drivers/amlogic/video_dev/Kconfig
index bdae1486..9233f498 100755
--- a/drivers/amlogic/video_dev/Kconfig
+++ b/drivers/amlogic/video_dev/Kconfig
@@ -16,7 +16,7 @@ config V4L_AMLOGIC_VIDEO2
 	select VIDEO_V4L2_COMMON
 	select VIDEOBUF_RESOURCE
 	select AM_GE2D
-    	default n
+	default n
 	---help---
 	  Select to enable "Amlogic v4l video2 device support.
 
diff --git a/drivers/amlogic/video_dev/Makefile b/drivers/amlogic/video_dev/Makefile
index 1e68c356..f525b6e8 100755
--- a/drivers/amlogic/video_dev/Makefile
+++ b/drivers/amlogic/video_dev/Makefile
@@ -1,11 +1,10 @@
 #
 # Makefile for the amlogic video device interface device drivers.
 #
-EXTRA_AFLAGS=-mfloat-abi=softfp -mfpu=neon
 amlvideodri-objs := amlvideo.o
 amlcm-objs := common/vfutil.o
 amlvideo2dri-objs := amlvideo2.o
 
 obj-$(CONFIG_V4L_AMLOGIC_VIDEO) +=amlcm.o
-obj-$(CONFIG_V4L_AMLOGIC_VIDEO) +=amlvideodri.o 
-obj-$(CONFIG_V4L_AMLOGIC_VIDEO2) +=amlvideo2dri.o 
+obj-$(CONFIG_V4L_AMLOGIC_VIDEO) +=amlvideodri.o
+obj-$(CONFIG_V4L_AMLOGIC_VIDEO2) +=amlvideo2dri.o
diff --git a/drivers/amlogic/video_dev/amlvideo.c b/drivers/amlogic/video_dev/amlvideo.c
old mode 100644
new mode 100755
index f7d5aa4b..84004953
--- a/drivers/amlogic/video_dev/amlvideo.c
+++ b/drivers/amlogic/video_dev/amlvideo.c
@@ -43,6 +43,9 @@
 #include <linux/amlogic/amports/vfp.h>
 
 #define AVMLVIDEO_MODULE_NAME "amlvideo"
+#define CREATE_TRACE_POINTS
+#include "trace/amlvideo.h"
+
 
 /* Wake up at about 30 fps */
 #define WAKE_NUMERATOR 30
@@ -60,11 +63,12 @@
 
 #define AMLVIDEO_POOL_SIZE 16
 static vfq_t q_ready;
+static vfq_t q_omx;
 extern bool omx_secret_mode;
+static u32 omx_frame_index = 0;
 static u8 first_frame;
 static u32 vpts_last;
 
-
 #define DUR2PTS(x) ((x) - ((x) >> 4))
 #define DUR2PTS_RM(x) ((x) & 0xf)
 
@@ -87,7 +91,7 @@ module_param(vid_limit, uint, 0644);
 MODULE_PARM_DESC(vid_limit, "capture memory limit in megabytes");
 
 static unsigned int freerun_mode = 0;
-module_param(freerun_mode, uint, 0666);
+module_param(freerun_mode, uint, 0664);
 MODULE_PARM_DESC(freerun_mode, "av synchronization int kernel");
 
 vframe_t* ppmgrvf = NULL;
@@ -154,6 +158,7 @@ static struct vivi_fmt formats[] = {
     };
 
 struct vframe_s *amlvideo_pool_ready[AMLVIDEO_POOL_SIZE+1];
+struct vframe_s *amlvideo_pool_omx[AMLVIDEO_POOL_SIZE+1];
 /* ------------------------------------------------------------------
  *           provider operations
  *-----------------------------------------------------------------*/
@@ -190,8 +195,8 @@ static int amlvideo_vf_states(vframe_states_t *states, void *op_arg) {
     //spin_lock_irqsave(&lock, flags);
     states->vf_pool_size    = AMLVIDEO_POOL_SIZE;
     states->buf_recycle_num = 0;
-    states->buf_free_num    =  AMLVIDEO_POOL_SIZE - vfq_level(&q_ready);
-    states->buf_avail_num   = vfq_level(&q_ready);
+    states->buf_free_num    = AMLVIDEO_POOL_SIZE - (vfq_level(&q_ready) + vfq_level(&q_omx));
+    states->buf_avail_num   = vfq_level(&q_ready) | (vfq_level(&q_omx) << 16);
     //spin_unlock_irqrestore(&lock, flags);
     return 0;
 }
@@ -316,8 +321,16 @@ static int video_receiver_event_fun(int type, void* data, void* private_data) {
             vf_reg_provider(&amlvideo_vf_prov);
             vf_notify_receiver(PROVIDER_NAME,VFRAME_EVENT_PROVIDER_START,NULL);
             vfq_init(&q_ready, AMLVIDEO_POOL_SIZE+1, &amlvideo_pool_ready[0]);
+            vfq_init(&q_omx, AMLVIDEO_POOL_SIZE+1, &amlvideo_pool_omx[0]);
         }
     }
+    else if (type == VFRAME_EVENT_PROVIDER_FR_HINT) {
+        vf_notify_receiver(PROVIDER_NAME,VFRAME_EVENT_PROVIDER_FR_HINT,data);
+    }
+    else if (type == VFRAME_EVENT_PROVIDER_FR_END_HINT) {
+        vf_notify_receiver(PROVIDER_NAME,VFRAME_EVENT_PROVIDER_FR_END_HINT,data);
+    }
+
     return 0;
 }
 
@@ -422,7 +435,8 @@ static int vidioc_querycap(struct file *file, void *priv, struct v4l2_capability
     strcpy(cap->card, "amlvideo");
     strlcpy(cap->bus_info, dev->v4l2_dev.name, sizeof(cap->bus_info));
     cap->version = AMLVIDEO_VERSION;
-    cap->capabilities = V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_STREAMING | V4L2_CAP_READWRITE;
+    cap->device_caps = V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_STREAMING | V4L2_CAP_READWRITE;
+    cap->capabilities = cap->device_caps | V4L2_CAP_DEVICE_CAPS;
     return 0;
 }
 
@@ -516,6 +530,32 @@ static int vidioc_querybuf(struct file *file, void *priv, struct v4l2_buffer *p)
 static int vidioc_qbuf(struct file *file, void *priv, struct v4l2_buffer *p) {
     int ret = 0;
     if (omx_secret_mode == true) {
+        trace_qbuf(p->index);
+        if (freerun_mode == 3) {
+
+            vframe_t *vf;
+
+            //skip dropped frames
+            while ((vf = vfq_peek(&q_omx)))
+            {
+                u32 index = (int)(vf->pts_us64);
+                if (index < p->index)
+                {
+                    printk("amlvideo vidioc_qbuf: skip index %u->%u\n",index, p->index);
+                    vf_put(vfq_pop(&q_omx), RECEIVER_NAME);
+                    continue;
+                }
+                else if (index == p->index)
+                {
+                    vfq_pop(&q_omx);
+                    if (!(p->flags & V4L2_BUF_FLAG_DONE))
+                        vfq_push(&q_ready, vf);
+                    else
+                        vf_put(vf, RECEIVER_NAME);
+                }
+                break;
+            }
+        }
         return ret;
     }
     if (ppmgrvf) {
@@ -564,16 +604,21 @@ static int freerun_cleancache_dqbuf(struct v4l2_buffer *p) {
     return ret;
 }
 
+static int my_wf_debug = 0;
+static int my_wb_debug = 0;
+
 static int freerun_dqbuf(struct v4l2_buffer *p) {
     int ret = 0;
+    int omx_ready = 0;
     if (omx_secret_mode == true) {
-        if (vfq_level(&q_ready)>AMLVIDEO_POOL_SIZE-1) {
-            msleep(10);
+        omx_ready = vfq_level(&q_ready);
+        if (omx_ready + vfq_level(&q_omx)> AMLVIDEO_POOL_SIZE-1) {
+            my_wb_debug++;
             return -EAGAIN;
         }
     }
     if (!vf_peek(RECEIVER_NAME)) {
-        msleep(10);
+        my_wf_debug++;
         return -EAGAIN;
     }
     if (omx_secret_mode != true) {
@@ -585,9 +630,7 @@ static int freerun_dqbuf(struct v4l2_buffer *p) {
         return -EAGAIN;
     }
     if (omx_secret_mode == true) {
-        vfq_push(&q_ready, ppmgrvf);
         p->index = 0;
-        p->timestamp.tv_sec = 0;
 
         if (ppmgrvf->pts) {
             first_frame = 1;
@@ -599,9 +642,21 @@ static int freerun_dqbuf(struct v4l2_buffer *p) {
             p->timestamp.tv_usec = vpts_last + (DUR2PTS(ppmgrvf->duration));
         }
         vpts_last = p->timestamp.tv_usec;
-        //printk("p->timestamp.tv_usec=%d\n",p->timestamp.tv_usec);
+        trace_dqbuf(p->index, my_wf_debug, my_wb_debug, omx_ready);
+        my_wf_debug = 0;
+        my_wb_debug = 0;
+
+        if (freerun_mode != 3)
+            vfq_push(&q_ready, ppmgrvf);
+        else
+        {
+            ppmgrvf->pts_us64 = omx_frame_index;
+            p->index = omx_frame_index++;
+            vfq_push(&q_omx, ppmgrvf);
+        }
+
         return ret;
-    }   
+    }
     if (ppmgrvf->pts != 0) {
         timestamp_vpts_set(ppmgrvf->pts);
     } else{
@@ -611,7 +666,7 @@ static int freerun_dqbuf(struct v4l2_buffer *p) {
 
 	if(!ppmgrvf->pts)
         ppmgrvf->pts_us64=ppmgrvf->pts*100/9;
-	
+
     if (unregFlag || startFlag) {
         if (ppmgrvf->pts == 0)
             timestamp_vpts_set(timestamp_pcrscr_get());
@@ -703,7 +758,7 @@ static int normal_dqbuf(struct v4l2_buffer *p) {
 static int vidioc_dqbuf(struct file *file, void *priv, struct v4l2_buffer *p) {
     int ret = 0;
 
-    if (freerun_mode == 1) {
+    if (freerun_mode == 1 || freerun_mode == 3) {
         ret = freerun_dqbuf(p);
     }else if (freerun_mode == 2) {
         ret = freerun_cleancache_dqbuf(p);
@@ -730,6 +785,7 @@ static int vidioc_streamon(struct file *file, void *priv, enum v4l2_buf_type i)
     ret = videobuf_streamon(&fh->vb_vidq);
     if (ret == 0)
         fh->is_streamed_on = 1;
+    trace_onoff(1);
     return ret;
 }
 
@@ -741,6 +797,7 @@ static int vidioc_streamoff(struct file *file, void *priv, enum v4l2_buf_type i)
     ret = videobuf_streamoff(&fh->vb_vidq);
     if (ret == 0)
         fh->is_streamed_on = 0;
+    trace_onoff(0);
     return ret;
 }
 
@@ -808,6 +865,7 @@ static int amlvideo_open(struct file *file) {
     unregFlag = 0;
     startFlag = 1;
     freerun_start = 0;
+    omx_frame_index = 0;
     mutex_unlock(&vfpMutex);
     mutex_lock(&dev->mutex);
     dev->users++;
@@ -908,7 +966,7 @@ static int amlvideo_mmap(struct file *file, struct vm_area_struct *vma) {
     return ret;
 }
 
-static const struct v4l2_file_operations amlvideo_fops = { .owner = THIS_MODULE, .open = amlvideo_open, .release = amlvideo_close, .read = amlvideo_read, .poll = amlvideo_poll, .ioctl = video_ioctl2, /* V4L2 ioctl handler */
+static const struct v4l2_file_operations amlvideo_fops = { .owner = THIS_MODULE, .open = amlvideo_open, .release = amlvideo_close, .read = amlvideo_read, .poll = amlvideo_poll, .unlocked_ioctl = video_ioctl2, /* V4L2 ioctl handler */
 .mmap = amlvideo_mmap, };
 
 static const struct v4l2_ioctl_ops amlvideo_ioctl_ops = {
@@ -934,7 +992,7 @@ static const struct v4l2_ioctl_ops amlvideo_ioctl_ops = {
 
 static struct video_device amlvideo_template = { .name = "amlvideo", .fops = &amlvideo_fops, .ioctl_ops = &amlvideo_ioctl_ops, .release = video_device_release,
 
-.tvnorms = V4L2_STD_525_60, .current_norm = V4L2_STD_NTSC_M , };
+.tvnorms = V4L2_STD_525_60, /* .current_norm = V4L2_STD_NTSC_M , */ };
 
 /* -----------------------------------------------------------------
  Initialization and module stuff
@@ -985,7 +1043,9 @@ static int __init amlvideo_create_instance(int inst) {
         goto unreg_dev;
 
     *vfd = amlvideo_template;
-    vfd->debug = debug;
+    // vfd->debug = debug;
+    vfd->v4l2_dev = &dev->v4l2_dev;
+
     ret = video_register_device(vfd, VFL_TYPE_GRABBER, video_nr);
     if (ret < 0)
         goto rel_vdev;
diff --git a/drivers/amlogic/video_dev/amlvideo2.c b/drivers/amlogic/video_dev/amlvideo2.c
old mode 100644
new mode 100755
index dccc43df..a628bf19
--- a/drivers/amlogic/video_dev/amlvideo2.c
+++ b/drivers/amlogic/video_dev/amlvideo2.c
@@ -59,7 +59,7 @@
 #define AVMLVIDEO2_MODULE_NAME "amlvideo2"
 
 //#define USE_SEMA_QBUF
-#define USE_VDIN_PTS
+//#define USE_VDIN_PTS
 
 //#define MUTLI_NODE
 #ifdef MUTLI_NODE
@@ -128,12 +128,18 @@ static int frameInv_adjust = 0;
 static int frameInv = 0;
 static vframe_t *tmp_vf = NULL;
 static int frame_inittime = 1;
-#define DEF_FRAMERATE 30 
+#define DEF_FRAMERATE 30
 
 static unsigned int vid_limit = 16;
 module_param(vid_limit, uint, 0644);
 MODULE_PARM_DESC(vid_limit, "capture memory limit in megabytes");
 
+static int capture_proc = 0;
+static int source_top_proc = 0;
+static int source_left_proc = 0;
+static int source_width_proc = 0;
+static int source_height_proc = 0;
+
 static struct v4l2_fract amlvideo2_frmintervals_active = {
 	.numerator = 1,
 	.denominator = DEF_FRAMERATE,
@@ -256,12 +262,12 @@ static struct amlvideo2_fmt formats[] = {
 		.name     = "RGB565 (BE)",
 		.fourcc   = V4L2_PIX_FMT_RGB565X, /* rrrrrggg gggbbbbb */
 		.depth    = 16,
-	},	
+	},
 	{
 		.name     = "BGR888 (24)",
 		.fourcc   = V4L2_PIX_FMT_BGR24, /* 24  BGR-8-8-8 */
 		.depth    = 24,
-	},		
+	},
 	{
 		.name     = "YUV420P",
 		.fourcc   = V4L2_PIX_FMT_YUV420,
@@ -331,7 +337,7 @@ struct amlvideo2_node {
 	struct mutex		   mutex;
 	int vid;
 	int                        users;
-	
+
 	struct amlvideo2_device *vid_dev;
 
 	/* various device info */
@@ -381,7 +387,7 @@ struct amlvideo2_output {
 	struct amlvideo2_frame_info* frame;
 };
 
-static struct v4l2_frmsize_discrete amlvideo2_prev_resolution[]= 
+static struct v4l2_frmsize_discrete amlvideo2_prev_resolution[]=
 {
 	{160,120},
 	{320,240},
@@ -426,9 +432,9 @@ int get_amlvideo2_canvas_index(struct amlvideo2_output* output, int start_canvas
 			(unsigned long)buf,
 			width*3, canvas_height,
 			CANVAS_ADDR_NOWRAP, CANVAS_BLKMODE_LINEAR);
-		break; 
+		break;
 	case V4L2_PIX_FMT_NV12:
-	case V4L2_PIX_FMT_NV21: 
+	case V4L2_PIX_FMT_NV21:
 		canvas_config(start_canvas,
 			(unsigned long)buf,
 			width, canvas_height,
@@ -483,9 +489,9 @@ int convert_canvas_index(struct amlvideo2_output* output, int start_canvas)
 	case V4L2_PIX_FMT_BGR24:
 	case V4L2_PIX_FMT_RGB24:
 		canvas = start_canvas;
-		break; 
+		break;
 	case V4L2_PIX_FMT_NV12:
-	case V4L2_PIX_FMT_NV21: 
+	case V4L2_PIX_FMT_NV21:
 		canvas = start_canvas | ((start_canvas+1)<<8);
 		break;
 	case V4L2_PIX_FMT_YVU420:
@@ -517,7 +523,7 @@ static int get_input_format(vframe_t* vf)
 			format =  GE2D_FORMAT_S16_YUV422|(GE2D_FORMAT_S16_YUV422T & (3<<3));
 		}else{
 			format =  GE2D_FORMAT_S16_YUV422;
-		} 
+		}
 	}else if(vf->type&VIDTYPE_VIU_NV21){
 		if(vf->type &VIDTYPE_INTERLACE_BOTTOM){
 			format =  GE2D_FORMAT_M24_NV21|(GE2D_FORMAT_M24_NV21B & (3<<3));
@@ -525,7 +531,7 @@ static int get_input_format(vframe_t* vf)
 			format =  GE2D_FORMAT_M24_NV21|(GE2D_FORMAT_M24_NV21T & (3<<3));
 		}else{
 			format =  GE2D_FORMAT_M24_NV21;
-		} 
+		}
 	} else{
 		if(vf->type &VIDTYPE_INTERLACE_BOTTOM){
 			format =  GE2D_FORMAT_M24_YUV420|(GE2D_FMT_M24_YUV420B & (3<<3));
@@ -546,6 +552,27 @@ static int get_input_format(vframe_t* vf)
 	return format;
 }
 
+static int get_input_format_no_interlace(vframe_t* vf)
+{
+	int format= GE2D_FORMAT_M24_NV21;
+	if(vf->type&VIDTYPE_VIU_422){
+		format =  GE2D_FORMAT_S16_YUV422;
+	}else if(vf->type&VIDTYPE_VIU_NV21){
+		format =  GE2D_FORMAT_M24_NV21;
+	} else{
+		format =  GE2D_FORMAT_M24_YUV420;
+	}
+	if(print_ifmt == 1){
+		printk("vf->type=%x, format=%x, w*h=%dx%d, canvas0=%x, canvas1=%x\n",
+			vf->type, format, vf->width, vf->height, vf->canvas0Addr, vf->canvas1Addr);
+
+		printk("vf->type=%x, VIDTYPE_INTERLACE_BOTTOM=%x, VIDTYPE_INTERLACE_TOP=%x\n",
+			vf->type, VIDTYPE_INTERLACE_BOTTOM, VIDTYPE_INTERLACE_TOP);
+		print_ifmt = 0;
+	}
+	return format;
+}
+
 static int get_interlace_input_format(vframe_t* vf, struct amlvideo2_output* output)
 {
 	int format= GE2D_FORMAT_M24_NV21;
@@ -631,7 +658,7 @@ static int get_output_format(int v4l2_format)
 			format = GE2D_FORMAT_S24_RGB ;
 			break;
 		case V4L2_PIX_FMT_RGB24:
-			format = GE2D_FORMAT_S24_BGR; 
+			format = GE2D_FORMAT_S24_BGR;
 			break;
 		case V4L2_PIX_FMT_NV12:
 			format = GE2D_FORMAT_M24_NV12;
@@ -644,8 +671,8 @@ static int get_output_format(int v4l2_format)
 			format = GE2D_FORMAT_S8_Y;
 			break;
 		default:
-			break;            
-	}   
+			break;
+	}
 	if(print_ofmt == 1){
 		printk("outputformat, v4l2_format=%x, format=%x\n",
 			v4l2_format, format);
@@ -697,7 +724,8 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 	src_top = 0;
 	src_left = 0;
 	src_width = vf->width;
-	src_height = vf->height/2;
+	//src_height = vf->height/2;
+	src_height = vf->height;
 
 	dst_top = 0;
 	dst_left = 0;
@@ -815,7 +843,7 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 	ge2d_config->src_para.top = 0;
 	ge2d_config->src_para.left = 0;
 	ge2d_config->src_para.width = vf->width;
-	ge2d_config->src_para.height = vf->height;
+	ge2d_config->src_para.height = vf->height/2;
 	/* printk("vf_width is %d , vf_height is %d \n",vf->width ,vf->height); */
 	ge2d_config->src2_para.mem_type = CANVAS_TYPE_INVALID;
 	ge2d_config->dst_para.canvas_index = output_canvas&0xff;
@@ -825,7 +853,7 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 		ge2d_config->dst_para.canvas_index = output_canvas;
 
 	ge2d_config->dst_para.mem_type = CANVAS_TYPE_INVALID;
-	ge2d_config->dst_para.format = get_output_format(output->v4l2_format)|GE2D_LITTLE_ENDIAN;     
+	ge2d_config->dst_para.format = (get_output_format(output->v4l2_format)|GE2D_LITTLE_ENDIAN)|(GE2D_FORMAT_M24_YUV420T & (3<<3));     
 	ge2d_config->dst_para.fill_color_en = 0;
 	ge2d_config->dst_para.fill_mode = 0;
 	ge2d_config->dst_para.x_rev = 0;
@@ -834,7 +862,7 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 	ge2d_config->dst_para.top = 0;
 	ge2d_config->dst_para.left = 0;
 	ge2d_config->dst_para.width = output->width;
-	ge2d_config->dst_para.height = output->height;
+	ge2d_config->dst_para.height = output->height/2;
 
 	if(current_mirror==1){
 		ge2d_config->dst_para.x_rev = 1;
@@ -862,7 +890,7 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 		printk("++ge2d configing error.\n");
 		return -1;
 	}
-	stretchblt_noalpha(context,src_left ,src_top ,src_width, src_height,output->frame->x,output->frame->y,output->frame->w,output->frame->h);
+	stretchblt_noalpha(context,src_left ,src_top/2 ,src_width, src_height/2,output->frame->x,output->frame->y/2,output->frame->w,output->frame->h/2);
 
 	/* for cr of  yuv420p or yuv420sp. */
 	if((output->v4l2_format==V4L2_PIX_FMT_YUV420)
@@ -873,9 +901,9 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 		ge2d_config->dst_planes[0].w = cd.width;
 		ge2d_config->dst_planes[0].h = cd.height;
 		ge2d_config->dst_para.canvas_index=(output_canvas>>8)&0xff;
-		ge2d_config->dst_para.format=GE2D_FORMAT_S8_CB|GE2D_LITTLE_ENDIAN;
+		ge2d_config->dst_para.format=(GE2D_FORMAT_S8_CB|GE2D_LITTLE_ENDIAN)|(GE2D_FORMAT_M24_YUV420T & (3<<3));
 		ge2d_config->dst_para.width = output->width/2;
-		ge2d_config->dst_para.height = output->height/2;
+		ge2d_config->dst_para.height = output->height/4;
 		ge2d_config->dst_xy_swap = 0;
 
 		if(current_mirror==1){
@@ -899,14 +927,14 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 			ge2d_config->dst_xy_swap = 1;
 			ge2d_config->dst_para.y_rev ^= 1;
 		}
-	
+
 		if(ge2d_context_config_ex(context,ge2d_config)<0) {
 			printk("++ge2d configing error.\n");
 			return -1;
 		}
-		stretchblt_noalpha(context, src_left, src_top, src_width, src_height,
-			output->frame->x/2,output->frame->y/2,output->frame->w/2,output->frame->h/2);
-	} 
+		stretchblt_noalpha(context, src_left, src_top/2, src_width, src_height/2,
+			output->frame->x/2,output->frame->y/4,output->frame->w/2,output->frame->h/4);
+	}
 	/* for cb of yuv420p or yuv420sp. */
 	if(output->v4l2_format==V4L2_PIX_FMT_YUV420||
 		output->v4l2_format==V4L2_PIX_FMT_YVU420) {
@@ -915,9 +943,9 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 		ge2d_config->dst_planes[0].w = cd.width;
 		ge2d_config->dst_planes[0].h = cd.height;
 		ge2d_config->dst_para.canvas_index=(output_canvas>>16)&0xff;
-		ge2d_config->dst_para.format=GE2D_FORMAT_S8_CR|GE2D_LITTLE_ENDIAN;
+		ge2d_config->dst_para.format=(GE2D_FORMAT_S8_CR|GE2D_LITTLE_ENDIAN)|(GE2D_FORMAT_M24_YUV420T & (3<<3));
 		ge2d_config->dst_para.width = output->width/2;
-		ge2d_config->dst_para.height = output->height/2;
+		ge2d_config->dst_para.height = output->height/4;
 		ge2d_config->dst_xy_swap = 0;
 
 		if(current_mirror==1){
@@ -946,8 +974,8 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 			printk("++ge2d configing error.\n");
 			return -1;
 		}
-		stretchblt_noalpha(context, src_left, src_top, src_width, src_height,
-			output->frame->x/2,output->frame->y/2,output->frame->w/2,output->frame->h/2);
+		stretchblt_noalpha(context, src_left, src_top/2, src_width, src_height/2,
+			output->frame->x/2,output->frame->y/4,output->frame->w/2,output->frame->h/4);
 	}
 
      //============================
@@ -957,7 +985,7 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 	src_top = 0;
 	src_left = 0;
 	src_width = vf->width;
-	src_height = vf->height/2;
+	src_height = vf->height;
 
 	dst_top = 0;
 	dst_left = 0;
@@ -1075,7 +1103,7 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 	ge2d_config->src_para.top = 0;
 	ge2d_config->src_para.left = 0;
 	ge2d_config->src_para.width = vf->width;
-	ge2d_config->src_para.height = vf->height;
+	ge2d_config->src_para.height = vf->height/2;
 	/* printk("vf_width is %d , vf_height is %d \n",vf->width ,vf->height); */
 	ge2d_config->src2_para.mem_type = CANVAS_TYPE_INVALID;
 	ge2d_config->dst_para.canvas_index = output_canvas&0xff;
@@ -1085,7 +1113,7 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 		ge2d_config->dst_para.canvas_index = output_canvas;
 
 	ge2d_config->dst_para.mem_type = CANVAS_TYPE_INVALID;
-	ge2d_config->dst_para.format = get_output_format(output->v4l2_format)|GE2D_LITTLE_ENDIAN;     
+	ge2d_config->dst_para.format = (get_output_format(output->v4l2_format)|GE2D_LITTLE_ENDIAN)|(GE2D_FORMAT_M24_YUV420B & (3<<3));;     
 	ge2d_config->dst_para.fill_color_en = 0;
 	ge2d_config->dst_para.fill_mode = 0;
 	ge2d_config->dst_para.x_rev = 0;
@@ -1094,7 +1122,7 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 	ge2d_config->dst_para.top = 0;
 	ge2d_config->dst_para.left = 0;
 	ge2d_config->dst_para.width = output->width;
-	ge2d_config->dst_para.height = output->height;
+	ge2d_config->dst_para.height = output->height/2;
 
 	if(current_mirror==1){
 		ge2d_config->dst_para.x_rev = 1;
@@ -1122,7 +1150,7 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 		printk("++ge2d configing error.\n");
 		return -1;
 	}
-	stretchblt_noalpha(context,src_left ,src_top ,src_width, src_height,output->frame->x,output->frame->y,output->frame->w,output->frame->h);
+	stretchblt_noalpha(context,src_left ,src_top/2 ,src_width, src_height/2,output->frame->x,output->frame->y/2,output->frame->w,output->frame->h/2);
 
 	/* for cr of  yuv420p or yuv420sp. */
 	if((output->v4l2_format==V4L2_PIX_FMT_YUV420)
@@ -1133,9 +1161,9 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 		ge2d_config->dst_planes[0].w = cd.width;
 		ge2d_config->dst_planes[0].h = cd.height;
 		ge2d_config->dst_para.canvas_index=(output_canvas>>8)&0xff;
-		ge2d_config->dst_para.format=GE2D_FORMAT_S8_CB|GE2D_LITTLE_ENDIAN;
+		ge2d_config->dst_para.format=(GE2D_FORMAT_S8_CB|GE2D_LITTLE_ENDIAN)|(GE2D_FORMAT_M24_YUV420B & (3<<3));
 		ge2d_config->dst_para.width = output->width/2;
-		ge2d_config->dst_para.height = output->height/2;
+		ge2d_config->dst_para.height = output->height/4;
 		ge2d_config->dst_xy_swap = 0;
 
 		if(current_mirror==1){
@@ -1159,14 +1187,14 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 			ge2d_config->dst_xy_swap = 1;
 			ge2d_config->dst_para.y_rev ^= 1;
 		}
-	
+
 		if(ge2d_context_config_ex(context,ge2d_config)<0) {
 			printk("++ge2d configing error.\n");
 			return -1;
 		}
-		stretchblt_noalpha(context, src_left, src_top, src_width, src_height,
-			output->frame->x/2,output->frame->y/2,output->frame->w/2,output->frame->h/2);
-	} 
+		stretchblt_noalpha(context, src_left, src_top/2, src_width, src_height/2,
+			output->frame->x/2,output->frame->y/4,output->frame->w/2,output->frame->h/4);
+	}
 	/* for cb of yuv420p or yuv420sp. */
 	if(output->v4l2_format==V4L2_PIX_FMT_YUV420||
 		output->v4l2_format==V4L2_PIX_FMT_YVU420) {
@@ -1175,9 +1203,9 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 		ge2d_config->dst_planes[0].w = cd.width;
 		ge2d_config->dst_planes[0].h = cd.height;
 		ge2d_config->dst_para.canvas_index=(output_canvas>>16)&0xff;
-		ge2d_config->dst_para.format=GE2D_FORMAT_S8_CR|GE2D_LITTLE_ENDIAN;
+		ge2d_config->dst_para.format=(GE2D_FORMAT_S8_CR|GE2D_LITTLE_ENDIAN)|(GE2D_FORMAT_M24_YUV420B & (3<<3));
 		ge2d_config->dst_para.width = output->width/2;
-		ge2d_config->dst_para.height = output->height/2;
+		ge2d_config->dst_para.height = output->height/4;
 		ge2d_config->dst_xy_swap = 0;
 
 		if(current_mirror==1){
@@ -1206,11 +1234,11 @@ int amlvideo2_ge2d_interlace_two_canvasAddr_process(vframe_t* vf, ge2d_context_t
 			printk("++ge2d configing error.\n");
 			return -1;
 		}
-		stretchblt_noalpha(context, src_left, src_top, src_width, src_height,
-			output->frame->x/2,output->frame->y/2,output->frame->w/2,output->frame->h/2);
+		stretchblt_noalpha(context, src_left, src_top/2, src_width, src_height/2,
+			output->frame->x/2,output->frame->y/4,output->frame->w/2,output->frame->h/4);
 	}
-	
-	
+
+
 	return output_canvas;
 }
 
@@ -1356,7 +1384,7 @@ int amlvideo2_ge2d_interlace_vdindata_process(vframe_t* vf, ge2d_context_t *cont
 		ge2d_config->dst_para.canvas_index = output_canvas;
 
 	ge2d_config->dst_para.mem_type = CANVAS_TYPE_INVALID;
-	ge2d_config->dst_para.format = get_output_format(output->v4l2_format)|GE2D_LITTLE_ENDIAN;     
+	ge2d_config->dst_para.format = get_output_format(output->v4l2_format)|GE2D_LITTLE_ENDIAN;
 	ge2d_config->dst_para.fill_color_en = 0;
 	ge2d_config->dst_para.fill_mode = 0;
 	ge2d_config->dst_para.x_rev = 0;
@@ -1430,14 +1458,14 @@ int amlvideo2_ge2d_interlace_vdindata_process(vframe_t* vf, ge2d_context_t *cont
 			ge2d_config->dst_xy_swap = 1;
 			ge2d_config->dst_para.y_rev ^= 1;
 		}
-	
+
 		if(ge2d_context_config_ex(context,ge2d_config)<0) {
 			printk("++ge2d configing error.\n");
 			return -1;
 		}
 		stretchblt_noalpha(context, src_left, src_top, src_width, src_height,
 			output->frame->x/2,output->frame->y/2,output->frame->w/2,output->frame->h/2);
-	} 
+	}
 	/* for cb of yuv420p or yuv420sp. */
 	if(output->v4l2_format==V4L2_PIX_FMT_YUV420||
 		output->v4l2_format==V4L2_PIX_FMT_YVU420) {
@@ -1495,7 +1523,8 @@ int amlvideo2_ge2d_interlace_one_canvasAddr_process(vframe_t* vf, ge2d_context_t
 	src_top = 0;
 	src_left = 0;
 	src_width = vf->width;
-	src_height = vf->height/2;
+	//src_height = vf->height/2;
+	src_height = vf->height;
 
 	dst_top = 0;
 	dst_left = 0;
@@ -1604,7 +1633,7 @@ int amlvideo2_ge2d_interlace_one_canvasAddr_process(vframe_t* vf, ge2d_context_t
 	ge2d_config->src_key.key_mode = 0;
 	ge2d_config->src_para.canvas_index=vf->canvas0Addr;
 	ge2d_config->src_para.mem_type = CANVAS_TYPE_INVALID;
-	ge2d_config->src_para.format = get_input_format(vf);
+	ge2d_config->src_para.format = get_input_format_no_interlace(vf);
 	ge2d_config->src_para.fill_color_en = 0;
 	ge2d_config->src_para.fill_mode = 0;
 	ge2d_config->src_para.x_rev = 0;
@@ -1613,7 +1642,7 @@ int amlvideo2_ge2d_interlace_one_canvasAddr_process(vframe_t* vf, ge2d_context_t
 	ge2d_config->src_para.top = 0;
 	ge2d_config->src_para.left = 0;
 	ge2d_config->src_para.width = vf->width;
-	ge2d_config->src_para.height = vf->height;
+	ge2d_config->src_para.height = vf->height/2;
 	/* printk("vf_width is %d , vf_height is %d \n",vf->width ,vf->height); */
 	ge2d_config->src2_para.mem_type = CANVAS_TYPE_INVALID;
 	ge2d_config->dst_para.canvas_index = output_canvas&0xff;
@@ -1623,7 +1652,7 @@ int amlvideo2_ge2d_interlace_one_canvasAddr_process(vframe_t* vf, ge2d_context_t
 		ge2d_config->dst_para.canvas_index = output_canvas;
 
 	ge2d_config->dst_para.mem_type = CANVAS_TYPE_INVALID;
-	ge2d_config->dst_para.format = get_output_format(output->v4l2_format)|GE2D_LITTLE_ENDIAN;     
+	ge2d_config->dst_para.format = get_output_format(output->v4l2_format)|GE2D_LITTLE_ENDIAN;
 	ge2d_config->dst_para.fill_color_en = 0;
 	ge2d_config->dst_para.fill_mode = 0;
 	ge2d_config->dst_para.x_rev = 0;
@@ -1660,7 +1689,7 @@ int amlvideo2_ge2d_interlace_one_canvasAddr_process(vframe_t* vf, ge2d_context_t
 		printk("++ge2d configing error.\n");
 		return -1;
 	}
-	stretchblt_noalpha(context,src_left ,src_top ,src_width, src_height,output->frame->x,output->frame->y,output->frame->w,output->frame->h);
+	stretchblt_noalpha(context,src_left ,src_top/2,src_width, src_height/2,output->frame->x,output->frame->y,output->frame->w,output->frame->h);
 
 	/* for cr of  yuv420p or yuv420sp. */
 	if((output->v4l2_format==V4L2_PIX_FMT_YUV420)
@@ -1697,14 +1726,14 @@ int amlvideo2_ge2d_interlace_one_canvasAddr_process(vframe_t* vf, ge2d_context_t
 			ge2d_config->dst_xy_swap = 1;
 			ge2d_config->dst_para.y_rev ^= 1;
 		}
-	
+
 		if(ge2d_context_config_ex(context,ge2d_config)<0) {
 			printk("++ge2d configing error.\n");
 			return -1;
 		}
-		stretchblt_noalpha(context, src_left, src_top, src_width, src_height,
+		stretchblt_noalpha(context, src_left, src_top/2, src_width, src_height/2,
 			output->frame->x/2,output->frame->y/2,output->frame->w/2,output->frame->h/2);
-	} 
+	}
 	/* for cb of yuv420p or yuv420sp. */
 	if(output->v4l2_format==V4L2_PIX_FMT_YUV420||
 		output->v4l2_format==V4L2_PIX_FMT_YVU420) {
@@ -1744,9 +1773,9 @@ int amlvideo2_ge2d_interlace_one_canvasAddr_process(vframe_t* vf, ge2d_context_t
 			printk("++ge2d configing error.\n");
 			return -1;
 		}
-		stretchblt_noalpha(context, src_left, src_top, src_width, src_height,
-			output->frame->x/2,output->frame->y/2,output->frame->w/2,output->frame->h/2);
-	}
+		stretchblt_noalpha(context, src_left, src_top/2, src_width, src_height/2,
+			output->frame->x/2,output->frame->y/2,output->frame->w/2,output->frame->h/2); }
+
 	return output_canvas;
 }
 
@@ -1764,6 +1793,28 @@ int amlvideo2_ge2d_pre_process(vframe_t* vf, ge2d_context_t *context,config_para
 	src_width = vf->width;
 	src_height = vf->height;
 
+	if (capture_proc == 1) {
+		if (( source_top_proc > 0 ) && ( source_top_proc < vf->height ))
+			src_top = source_top_proc;
+		else
+			src_top = 0;
+
+		if (( source_left_proc > 0 ) && ( source_left_proc < vf->width ))
+			src_left = source_left_proc;
+		else
+			src_left = 0;
+
+		if (( source_width_proc > 0 ) && ( source_width_proc < ( vf->width - src_left )))
+			src_width = source_width_proc;
+		else
+			src_width = vf->width - src_left;
+
+		if ( source_height_proc > 0 && ( source_height_proc < ( vf->height - src_top )))
+			src_height = source_height_proc;
+		else
+			src_height = vf->height - src_top;
+	}
+
 	dst_top = 0;
 	dst_left = 0;
 	dst_width = output->width;
@@ -1779,7 +1830,9 @@ int amlvideo2_ge2d_pre_process(vframe_t* vf, ge2d_context_t *context,config_para
 	if(src_width<src_height)
 		cur_angle = (cur_angle+90)%360;
 
-       output_axis_adjust(src_width,src_height,&dst_width,&dst_height,cur_angle);
+	if (capture_proc == 0)
+		output_axis_adjust(src_width,src_height,&dst_width,&dst_height,cur_angle);
+
 	dst_top = (output->height-dst_height)/2;
 	dst_left = (output->width-dst_width)/2;
 	dst_top = dst_top&0xfffffffe;
@@ -1890,7 +1943,7 @@ int amlvideo2_ge2d_pre_process(vframe_t* vf, ge2d_context_t *context,config_para
 		ge2d_config->dst_para.canvas_index = output_canvas;
 
 	ge2d_config->dst_para.mem_type = CANVAS_TYPE_INVALID;
-	ge2d_config->dst_para.format = get_output_format(output->v4l2_format)|GE2D_LITTLE_ENDIAN;     
+	ge2d_config->dst_para.format = get_output_format(output->v4l2_format)|GE2D_LITTLE_ENDIAN;
 	ge2d_config->dst_para.fill_color_en = 0;
 	ge2d_config->dst_para.fill_mode = 0;
 	ge2d_config->dst_para.x_rev = 0;
@@ -1964,14 +2017,14 @@ int amlvideo2_ge2d_pre_process(vframe_t* vf, ge2d_context_t *context,config_para
 			ge2d_config->dst_xy_swap = 1;
 			ge2d_config->dst_para.y_rev ^= 1;
 		}
-	
+
 		if(ge2d_context_config_ex(context,ge2d_config)<0) {
 			printk("++ge2d configing error.\n");
 			return -1;
 		}
 		stretchblt_noalpha(context, src_left, src_top, src_width, src_height,
 			output->frame->x/2,output->frame->y/2,output->frame->w/2,output->frame->h/2);
-	} 
+	}
 	/* for cb of yuv420p or yuv420sp. */
 	if(output->v4l2_format==V4L2_PIX_FMT_YUV420||
 		output->v4l2_format==V4L2_PIX_FMT_YVU420) {
@@ -2038,7 +2091,7 @@ static int amlvideo2_fillbuff(struct amlvideo2_fh *fh, struct amlvideo2_node_buf
 	dprintk(node->vid_dev,1,"%s\n", __func__);
 	if (!vbuf)
 		return -1;
-	
+
 	//memset(&ge2d_config,0,sizeof(config_para_ex_t));
 	memset(&output,0,sizeof(struct amlvideo2_output));
 
@@ -2104,7 +2157,7 @@ static int amlvideo2_fillbuff(struct amlvideo2_fh *fh, struct amlvideo2_node_buf
 				src_canvas = amlvideo2_ge2d_interlace_two_canvasAddr_process(vf,node->context,&ge2d_config,&output);
 			}
 		}else{
-			src_canvas = amlvideo2_ge2d_pre_process(vf,node->context,&ge2d_config,&output); 
+			src_canvas = amlvideo2_ge2d_pre_process(vf,node->context,&ge2d_config,&output);
 		}
 	}
 
@@ -2120,8 +2173,11 @@ static unsigned print_ivals=0;
 module_param(print_ivals, uint, 0644);
 MODULE_PARM_DESC(print_ivals, "print current intervals!!");
 
-//#define TEST_LATENCY
+#define TEST_LATENCY
 #ifdef TEST_LATENCY
+static unsigned print_latecny=0;
+module_param(print_latecny, uint, 0644);
+MODULE_PARM_DESC(print_latecny, "print current latency!!");
 static int total_latency = 0;
 static int total_latency_out = 0;
 static long long cur_time = 0;
@@ -2139,8 +2195,8 @@ static int  amlvideo2_thread_tick(struct amlvideo2_fh *fh)
 	unsigned diff = 0;
 	bool no_frame = false;
 	vframe_t *vf = NULL;
-
 	unsigned long flags = 0;
+	int active_duration = 0;
 
 	dprintk(node->vid_dev, 1, "Thread tick\n");
 
@@ -2171,7 +2227,9 @@ static int  amlvideo2_thread_tick(struct amlvideo2_fh *fh)
 	spin_lock_irqsave(&node->slock, flags);
 	if (list_empty(&dma_q->active)){
 		dprintk(node->vid_dev, 1, "No active queue to serve\n");
-		goto unlock;
+
+		spin_unlock_irqrestore(&node->slock, flags);
+		return -1;
 	}
 
 	buf = list_entry(dma_q->active.next,
@@ -2185,12 +2243,23 @@ static int  amlvideo2_thread_tick(struct amlvideo2_fh *fh)
 			vf_inqueue(vf,node->recv.name);
 			vf = vf_get(node->recv.name);
 		}
+		if((node->p_type == AML_PROVIDE_HDMIIN_VDIN0)||(node->p_type == AML_PROVIDE_HDMIIN_VDIN1)){
+			if(((vf->type &VIDTYPE_TYPEMASK) == VIDTYPE_INTERLACE_BOTTOM)&&(vf->canvas0Addr == vf->canvas1Addr)){
+				vf_inqueue(vf, node->recv.name);
+				no_frame = true;
+				vf = NULL;
+			}
+		}
 	}
 
 #ifdef USE_VDIN_PTS
 	if(no_frame)
 		goto unlock;
 	if(frame_inittime == 1){
+		if(tmp_vf){
+			vf_inqueue(tmp_vf,node->recv.name);
+			tmp_vf = NULL;
+		}
 		frameInv_adjust = 0;
 		frameInv = 0;
 		thread_ts1.tv_sec = vf->pts_us64& 0xFFFFFFFF;
@@ -2205,16 +2274,21 @@ static int  amlvideo2_thread_tick(struct amlvideo2_fh *fh)
 		}
 	}
 #else
-	int active_duration = 0;
 	if(frame_inittime == 1){
-	   	if(no_frame)
+		if(tmp_vf){
+			vf_inqueue(tmp_vf,node->recv.name);
+			tmp_vf = NULL;
+		}
+		if(no_frame)
 			goto unlock;
 		frameInv_adjust = 0;
 		frameInv = 0;
-		do_gettimeofday( &thread_ts1);
+		do_gettimeofday(&thread_ts1);
 		frame_inittime = 0;
 	}else{
 		do_gettimeofday( &thread_ts2);
+		//thread_ts2.tv_sec = vf->pts_us64& 0xFFFFFFFF;
+		//thread_ts2.tv_usec = vf->pts;
 		diff = thread_ts2.tv_sec - thread_ts1.tv_sec;
 		diff = diff*1000000 + thread_ts2.tv_usec - thread_ts1.tv_usec;
 		frameInv += diff;
@@ -2260,10 +2334,13 @@ static int  amlvideo2_thread_tick(struct amlvideo2_fh *fh)
 
 // test latency
 #ifdef TEST_LATENCY
-	do_gettimeofday(&test_time);
+	if(print_latecny)
 	{
-		int timeNow64 = ((test_time.tv_sec & 0xFFFFFFFF)*1000*1000) + (test_time.tv_usec);
-		int timePts =  ((vf->pts_us64 & 0xFFFFFFFF)*1000*1000) + (vf->pts);
+		int timeNow64, timePts;
+		do_gettimeofday(&test_time);
+		timeNow64 = ((test_time.tv_sec & 0xFFFFFFFF)*1000*1000) + (test_time.tv_usec);
+		//timePts =  ((vf->pts_us64 & 0xFFFFFFFF)*1000*1000) + (vf->pts);
+		timePts =  ((thread_ts2.tv_sec & 0xFFFFFFFF)*1000*1000) + (thread_ts2.tv_usec);
 		//printk("amlvideo2 in  num:%d delay:%d\n", timePts, (timeNow64 - timePts)/1000);
 		if(cur_time == test_time.tv_sec){
 			total_latency += (int)((timeNow64 - timePts)/1000);
@@ -2285,6 +2362,9 @@ static int  amlvideo2_thread_tick(struct amlvideo2_fh *fh)
 	buf->vb.ts.tv_usec = vf->pts;
 	thread_ts1.tv_sec = vf->pts_us64& 0xFFFFFFFF;
 	thread_ts1.tv_usec = vf->pts;
+#else
+	buf->vb.ts.tv_sec = thread_ts2.tv_sec & 0xFFFFFFFF;
+	buf->vb.ts.tv_usec = thread_ts2.tv_usec;
 #endif
 	vf_inqueue(vf,node->recv.name);
 
@@ -2300,10 +2380,12 @@ static int  amlvideo2_thread_tick(struct amlvideo2_fh *fh)
 
 // test latency
 #ifdef TEST_LATENCY
-	do_gettimeofday(&test_time);
+	if(print_latecny)
 	{
-		int timeNow64_out = ((test_time.tv_sec & 0xFFFFFFFF)*1000*1000) + (test_time.tv_usec);
-		int timePts_out =  ((buf->vb.ts.tv_sec & 0xFFFFFFFF)*1000*1000) + (buf->vb.ts.tv_usec);
+		int timeNow64_out, timePts_out;
+		do_gettimeofday(&test_time);
+		timeNow64_out = ((test_time.tv_sec & 0xFFFFFFFF)*1000*1000) + (test_time.tv_usec);
+		timePts_out =  ((buf->vb.ts.tv_sec & 0xFFFFFFFF)*1000*1000) + (buf->vb.ts.tv_usec);
 		//printk("amlvideo2 out num:%d delay:%d\n", timePts_out, (timeNow64_out - timePts_out)/1000);
 		if(cur_time_out == test_time.tv_sec){
 			total_latency_out += (timeNow64_out - timePts_out)/1000;
@@ -2374,13 +2456,14 @@ static int amlvideo2_thread(void *data)
 		if(!node->vidq.task_running){
 			break;
 		}
-		amlvideo2_sleep(fh); 
-		if (kthread_should_stop()) 			
-			break; 	
+		amlvideo2_sleep(fh);
+		if (kthread_should_stop())
+			break;
 	}
 	while(!kthread_should_stop()){
 		msleep(10);
 	}
+	tmp_vf = NULL;
 	dprintk(node->vid_dev, 1, "thread: exit\n");
 	return ret;
 }
@@ -2394,6 +2477,8 @@ static int amlvideo2_start_thread(struct amlvideo2_fh *fh)
 #endif
 	dprintk(node->vid_dev, 1, "%s\n", __func__);
 
+    dma_q->task_running = 1;
+
 #ifdef MUTLI_NODE
 	dma_q->kthread = kthread_run(amlvideo2_thread, fh, (node->vid==0)?"amlvideo2-0":"amlvideo2-1");
 #else
@@ -2406,7 +2491,7 @@ static int amlvideo2_start_thread(struct amlvideo2_fh *fh)
 	}
 	/* Wakes thread */
 	//wake_up_interruptible(&dma_q->wq);
-	dma_q->task_running = 1;
+
 	dprintk(node->vid_dev, 1, "returning from %s\n", __func__);
 	return 0;
 }
@@ -2449,7 +2534,7 @@ aml_provider_type get_provider_type(const char* name, int input)
 	}else{
 		type = AML_PROVIDE_MAX;
 	}
-	return type;	
+	return type;
 }
 
 aml_provider_type get_sub_receiver_type(const char* name)
@@ -2464,7 +2549,7 @@ aml_provider_type get_sub_receiver_type(const char* name)
 		type = AML_RECEIVER_MAX;
 		printk("type is not certain\n");
 	}
-	return type;	
+	return type;
 }
 /* ------------------------------------------------------------------
  *           provider operations
@@ -2664,9 +2749,10 @@ static int vidioc_querycap(struct file *file, void  *priv,
 	strcpy(cap->card, "amlvideo2");
 	strlcpy(cap->bus_info, node->vid_dev->v4l2_dev.name, sizeof(cap->bus_info));
 	cap->version = AMLVIDEO2_VERSION;
-	cap->capabilities =	V4L2_CAP_VIDEO_CAPTURE |
+	cap->device_caps =	V4L2_CAP_VIDEO_CAPTURE |
 				V4L2_CAP_STREAMING     |
 				V4L2_CAP_READWRITE;
+	cap->capabilities = cap->device_caps | V4L2_CAP_DEVICE_CAPS;
 	return 0;
 }
 
@@ -2706,7 +2792,7 @@ static int vidioc_try_fmt_vid_cap(struct file *file, void *priv,
 	struct amlvideo2_fmt *fmt = NULL;
 	enum v4l2_field field;
 	unsigned int maxw, maxh;
-	
+
 	fmt = get_format(f);
 	if (!fmt) {
 		dprintk(node->vid_dev, 1, "Fourcc format (0x%08x) invalid.\n", f->fmt.pix.pixelformat);
@@ -2893,6 +2979,9 @@ static tvin_scan_mode_t vmode2scan_mode(vmode_t	mode)
 		case VMODE_576CVBS:
 		case VMODE_1080I:
 		case VMODE_1080I_50HZ:
+		#ifdef CONFIG_AML_VOUT_FRAMERATE_AUTOMATION
+    		case VMODE_1080I_59HZ:
+		#endif
 			scan_mode = TVIN_SCAN_MODE_INTERLACED;
 			break;
 		case VMODE_480P:
@@ -2914,6 +3003,16 @@ static tvin_scan_mode_t vmode2scan_mode(vmode_t	mode)
 		case VMODE_LVDS_1080P:
 		case VMODE_LVDS_1080P_50HZ:
 		case VMODE_LVDS_768P:
+	#if MESON_CPU_TYPE >= MESON_CPU_TYPE_MESON8
+	#ifdef CONFIG_AML_VOUT_FRAMERATE_AUTOMATION
+    case VMODE_480P_59HZ:
+		case VMODE_720P_59HZ:
+		case VMODE_1080P_59HZ:
+		case VMODE_1080P_23HZ:
+		case VMODE_4K2K_29HZ:
+		case VMODE_4K2K_23HZ:
+	#endif
+	#endif
 			scan_mode = TVIN_SCAN_MODE_PROGRESSIVE;
 			break;
 		default:
@@ -2984,7 +3083,7 @@ static int vidioc_streamon(struct file *file, void *priv, enum v4l2_buf_type i)
 			dst_w = vinfo->width;
 			dst_h = vinfo->height;
 		}
-		output_axis_adjust(vinfo->width,vinfo->height, (int *)&dst_w,(int *)&dst_h,0);	
+		output_axis_adjust(vinfo->width,vinfo->height, (int *)&dst_w,(int *)&dst_h,0);
 	}
 	para.dest_hactive = dst_w;
 	para.dest_vactive = dst_h;
@@ -2992,17 +3091,17 @@ static int vidioc_streamon(struct file *file, void *priv, enum v4l2_buf_type i)
 		para.dest_vactive = para.dest_vactive/2;
 	}
 	printk("amlvideo2--vidioc_streamon: para.h_active: %d, para.v_active: %d"
-		"para.dest_hactive: %d, para.dest_vactive: %d, fh->width: %d, fh->height: %d \n",
-		para.h_active,para.v_active, para.dest_hactive, para.dest_vactive,fh->width,fh->height);
+		"para.dest_hactive: %d, para.dest_vactive: %d, fh->width: %d, fh->height: %d, vinfo->mode: %d,para.scan_mode: %d\n",
+		para.h_active,para.v_active, para.dest_hactive, para.dest_vactive,fh->width,fh->height,vinfo->mode,para.scan_mode);
 
 	vops->start_tvin_service(node->vdin_device_num,&para);
 
 start:
-	fh->is_streamed_on = 1;
-	frameInv_adjust = 0;
-	frameInv = 0;
-	tmp_vf = NULL;
 	frame_inittime = 1;
+	fh->is_streamed_on = 1;
+	//frameInv_adjust = 0;
+	//frameInv = 0;
+	//tmp_vf = NULL;
 	do_gettimeofday( &thread_ts1);
 #ifdef TEST_LATENCY
 	cur_time  = cur_time_out = thread_ts1.tv_sec;
@@ -3093,7 +3192,7 @@ static int vidioc_s_std(struct file *file, void *priv, v4l2_std_id i)
 
 /* --- controls ---------------------------------------------- */
 
-static int amlvideo2_setting(struct amlvideo2_node *node,int PROP_ID,int value,int index) 
+static int amlvideo2_setting(struct amlvideo2_node *node,int PROP_ID,int value,int index)
 {
 	int ret=0;
 	switch(PROP_ID)  {
@@ -3107,7 +3206,7 @@ static int amlvideo2_setting(struct amlvideo2_node *node,int PROP_ID,int value,i
 		break;
 	}
 	return ret;
-    
+
 }
 
 static int vidioc_queryctrl(struct file *file, void *priv,
@@ -3180,6 +3279,25 @@ static int vidioc_s_ctrl(struct file *file, void *priv,
 	return -EINVAL;
 }
 
+static int vidioc_s_crop(struct file *file, void *fh,
+					const struct v4l2_crop *a)
+{
+	if (a->c.width == 0 || a->c.height == 0) {
+		printk("disable capture proc\n");
+		capture_proc = 0;
+		source_top_proc = source_left_proc = source_width_proc = source_height_proc = 0;
+	} else {
+		printk("enable capture proc\n");
+		source_top_proc = a->c.top;
+		source_left_proc = a->c.left;
+		source_width_proc = a->c.width;
+		source_height_proc = a->c.height;
+		capture_proc = 1;
+	}
+
+	return 0;
+}
+
 /* ------------------------------------------------------------------
 	File operations for the device
    ------------------------------------------------------------------*/
@@ -3260,7 +3378,7 @@ static int amlvideo2_open(struct file *file)
 	fh->width    = 1920;
 	fh->height   = 1080;
 	fh->f_flags  = file->f_flags;
-	
+
 	fh->node->res.priv = (void*)fh;
 	res = &fh->node->res;
 	videobuf_queue_res_init(&fh->vb_vidq, &amlvideo2_qops,
@@ -3316,13 +3434,15 @@ static int amlvideo2_close(struct file *file)
 	if(AML_RECEIVER_NONE == node->r_type){
 #if MESON_CPU_TYPE >= MESON_CPU_TYPE_MESON6
 		switch_mod_gate_by_name("ge2d", 0);
-#endif	
+#endif
 	}
 	node->users--;
 	amlvideo2_frmintervals_active.numerator = 1;
 	amlvideo2_frmintervals_active.denominator = DEF_FRAMERATE;
 	//node->provider = NULL;
 	mutex_unlock(&node->mutex);
+
+	capture_proc = source_top_proc = source_left_proc = source_width_proc = source_height_proc = 0;
 	return 0;
 }
 
@@ -3351,7 +3471,7 @@ static const struct v4l2_file_operations amlvideo2_fops = {
 	.release        = amlvideo2_close,
 	.read           = amlvideo2_read,
 	.poll		= amlvideo2_poll,
-	.ioctl          = video_ioctl2, /* V4L2 ioctl handler */
+	.unlocked_ioctl          = video_ioctl2, /* V4L2 ioctl handler */
 	.mmap           = amlvideo2_mmap,
 };
 
@@ -3377,6 +3497,7 @@ static const struct v4l2_ioctl_ops amlvideo2_ioctl_ops = {
 	.vidioc_enum_frameintervals =vidioc_enum_frameintervals,
 	.vidioc_s_input       = vidioc_s_input,
 	.vidioc_g_input       = vidioc_g_input,
+	.vidioc_s_crop        = vidioc_s_crop,
 #ifdef CONFIG_VIDEO_V4L1_COMPAT
 	.vidiocgmbuf          = vidiocgmbuf,
 #endif
@@ -3389,7 +3510,7 @@ static struct video_device amlvideo2_template = {
 	.release	= video_device_release,
 
 	.tvnorms              = V4L2_STD_525_60,
-	.current_norm         = V4L2_STD_NTSC_M,
+	// .current_norm         = V4L2_STD_NTSC_M,
 };
 
 static int amlvideo2_receiver_event_fun(int type, void* data, void* private_data)
@@ -3405,11 +3526,11 @@ static int amlvideo2_receiver_event_fun(int type, void* data, void* private_data
 			break;
 		case VFRAME_EVENT_PROVIDER_QUREY_STATE:
 			if(vfq_level(&q_ready)){
-				return RECEIVER_ACTIVE ;		
+				return RECEIVER_ACTIVE ;
 			}else{
 				return RECEIVER_INACTIVE;
 			}
-			break;   
+			break;
 		case VFRAME_EVENT_PROVIDER_START:
 #if MESON_CPU_TYPE >= MESON_CPU_TYPE_MESON6
 			switch_mod_gate_by_name("ge2d", 1);
@@ -3439,7 +3560,7 @@ static int amlvideo2_receiver_event_fun(int type, void* data, void* private_data
 			}
 
 			break;
-		case VFRAME_EVENT_PROVIDER_UNREG: 
+		case VFRAME_EVENT_PROVIDER_UNREG:
 			node->provide_ready = 0;
 			printk("r_type=%d,p_type=%d\n", node->r_type, node->p_type);
 			if( AML_RECEIVER_NONE != node->r_type){
@@ -3513,18 +3634,18 @@ static int amlvideo2_create_node(struct platform_device *pdev)
 
 	for(i = 0; i<vid_dev->node_num;i++){
 		vid_dev->node[i] = NULL;
-		ret = -ENOMEM;	
-#if 0		
+		ret = -ENOMEM;
+#if 0
 		res = platform_get_resource(pdev, IORESOURCE_MEM, i);
 #else
 		res = &memobj;
-    		ret = find_reserve_block(pdev->dev.of_node->name,i);
-    		if(ret < 0){
-        		printk("\namlvideo2 memory resource undefined.\n");
-        		return -EFAULT;
-    		}
-    		res->start = (phys_addr_t)get_reserve_block_addr(ret);
-    		res->end = res->start+ (phys_addr_t)get_reserve_block_size(ret)-1;
+		ret = find_reserve_block(pdev->dev.of_node->name,i);
+		if(ret < 0){
+			printk("\namlvideo2 memory resource undefined.\n");
+			return -EFAULT;
+		}
+		res->start = (phys_addr_t)get_reserve_block_addr(ret);
+		res->end = res->start+ (phys_addr_t)get_reserve_block_size(ret)-1;
 #endif
 		if(!res)
 			break;
@@ -3536,7 +3657,7 @@ static int amlvideo2_create_node(struct platform_device *pdev)
 		vid_node->res.start = res->start;
 		vid_node->res.end =res->end;
 		vid_node->res.magic = MAGIC_RE_MEM;
-		vid_node->res.priv = NULL;		
+		vid_node->res.priv = NULL;
 		vid_node->context = create_ge2d_work_queue();
 		if(!vid_node->context){
 			kfree(vid_node);
@@ -3558,7 +3679,7 @@ static int amlvideo2_create_node(struct platform_device *pdev)
 			break;
 		}
 		*vfd = amlvideo2_template;
-		vfd->debug = debug;
+		// vfd->debug = debug;
 		ret = video_register_device(vfd, VFL_TYPE_GRABBER, video_nr);
 		if (ret < 0){
 			ret = -ENODEV;
@@ -3590,7 +3711,7 @@ static int amlvideo2_create_node(struct platform_device *pdev)
 #else
 		vf_receiver_init(&vid_node->recv, RECEIVER_NAME, &video_vf_receiver, (void*)vid_node);
 #endif
-       	vf_reg_receiver(&vid_node->recv);
+	vf_reg_receiver(&vid_node->recv);
 		vf_provider_init(&amlvideo2_vf_prov, DEVICE_NAME ,&amlvideo2_vf_provider, NULL);
 		vid_dev->node[i] = vid_node;
 		v4l2_info(&vid_dev->v4l2_dev, "V4L2 device registered as %s\n", video_device_node_name(vfd));
@@ -3599,7 +3720,7 @@ static int amlvideo2_create_node(struct platform_device *pdev)
 
 	if(ret)
 		amlvideo2_release_node(vid_dev);
-	
+
 	return ret;
 }
 
@@ -3607,7 +3728,7 @@ static int amlvideo2_driver_probe(struct platform_device *pdev)
 {
 	int ret = 0;
 	struct amlvideo2_device *dev = NULL;
-	
+
 	if(of_get_property(pdev->dev.of_node, "reserve-memory", NULL))
 		pdev->num_resources = MAX_SUB_DEV_NODE;
 	if (pdev->num_resources == 0) {
diff --git a/drivers/amlogic/video_dev/common/vfp-queue.h b/drivers/amlogic/video_dev/common/vfp-queue.h
old mode 100644
new mode 100755
diff --git a/drivers/amlogic/video_dev/common/vfutil.c b/drivers/amlogic/video_dev/common/vfutil.c
old mode 100644
new mode 100755
index 772b166f..fe6d6577
--- a/drivers/amlogic/video_dev/common/vfutil.c
+++ b/drivers/amlogic/video_dev/common/vfutil.c
@@ -1,7 +1,7 @@
-/* 
- * 
+/*
+ *
  */
- 
+
 #include <linux/version.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
diff --git a/drivers/amlogic/video_dev/trace/amlvideo.h b/drivers/amlogic/video_dev/trace/amlvideo.h
new file mode 100644
index 00000000..12e954a3
--- /dev/null
+++ b/drivers/amlogic/video_dev/trace/amlvideo.h
@@ -0,0 +1,69 @@
+#undef TRACE_SYSTEM
+#define TRACE_INCLUDE_PATH ../../drivers/amlogic/video_dev/trace
+#define TRACE_SYSTEM amlvideo
+
+#if !defined(_TRACE_IONVIDEO_H) || defined(TRACE_HEADER_MULTI_READ)
+#define _TRACE_IONVIDEO_H
+
+#include <linux/tracepoint.h>
+
+TRACE_EVENT(qbuf,
+    TP_PROTO(int idx),
+
+    TP_ARGS(idx),
+
+    TP_STRUCT__entry(
+            __field(u32, idx)
+    ),
+
+    TP_fast_assign(
+            __entry->idx = idx;
+    ),
+
+    TP_printk("[Q]: buf%d", __entry->idx)
+);
+
+TRACE_EVENT(dqbuf,
+    TP_PROTO(int idx, int wf, int wb, int wq),
+
+    TP_ARGS(idx, wf, wb, wq),
+
+    TP_STRUCT__entry(
+            __field(u32, idx)
+            __field(u32, wf)
+            __field(u32, wb)
+            __field(u32, wq)
+    ),
+
+    TP_fast_assign(
+            __entry->idx = idx;
+            __entry->wf = wf;
+            __entry->wb = wb;
+            __entry->wq = wq;
+	),
+
+    TP_printk("\t\t[D]: buf%d wf:%d, wb:%d, qlv:%d", __entry->idx,
+        __entry->wf, __entry->wb, __entry->wq)
+);
+
+TRACE_EVENT(onoff,
+    TP_PROTO(int que),
+
+    TP_ARGS(que),
+
+    TP_STRUCT__entry(
+            __field(u32, que)
+    ),
+
+    TP_fast_assign(
+            __entry->que = que;
+    ),
+
+    TP_printk("\t\t @[%s]@", __entry->que? "StreamON": "SteamOFF")
+);
+
+#endif /* if !defined(_TRACE_SYNC_H) || defined(TRACE_HEADER_MULTI_READ) */
+
+/* This part must be outside protection */
+#include <trace/define_trace.h>
+
